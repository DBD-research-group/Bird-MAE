# @package _global_
defaults:
  - override /callbacks: default
  - override /data/dataset: audioset_balanced
  - override /data/loaders: audioset_balanced
  - override /data/transform: melbank_as
  - override /logger: mlflow
  - override /module/network: vit_base_16
  - override /module/optimizer: adamw
  - override /module/scheduler: cosine
  - override /module/loss: asymmetric_loss
  - override /module/metric: map
  - override /paths: workstation
  - override /trainer: single_gpu

seed: 42
start_time: ${now:%Y-%m-%d_%H%M%S}
task_name: "finetune_asb"

train: true
test: true

trainer:
  limit_val_batches: 1.0
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 1
  max_epochs: 30
  
data:
  loaders:
    train: 
      num_workers: 24
      batch_size: 64
      shuffle: true
      drop_last: true
logger:
  experiment_name: amae_rep

module:
  optimizer:
    target:
      #lr: 1e-3
      lr: 3e-4
    extras:
      layer_decay: 0.75
  network:
    pretrained_weights_path: ${paths.root_dir}/weights/amae_as2m_pretrained.pth
    ema_update_rate: null
    freeze_backbone: True